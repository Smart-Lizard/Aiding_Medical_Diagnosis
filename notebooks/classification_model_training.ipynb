{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This version of the code will give you detailed feedback on the model’s performance throughout the training process, with clear metrics for both loss and accuracy. You can visually assess how well the model is learning and whether there are any signs of overfitting or underfitting based on the plots of training and validation metrics.\n",
        "\n",
        "Here’s an updated version of the code with these improvements:\n"
      ],
      "metadata": {
        "id": "UdqHD-bxenKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "7caX8o6an07P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision medmnist\n",
        "!pip install git+https://github.com/MedMNIST/MedMNIST.git"
      ],
      "metadata": {
        "id": "n23m6_bWnupn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "7J7h_2yquRcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, models\n",
        "import medmnist\n",
        "from medmnist import INFO, PathMNIST\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Load and preprocess dataset (224x224 resolution)\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Pretrained model normalization\n",
        "])\n",
        "\n",
        "info = INFO['pathmnist']\n",
        "DataClass = getattr(medmnist, info['python_class'])\n",
        "\n",
        "# Load the PathMNIST dataset with the desired resolution:\n",
        "train_dataset = PathMNIST(split='train', download=True, transform=transform, as_rgb=True, size=224)\n",
        "val_dataset = PathMNIST(split='val', download=True, transform=transform, as_rgb=True, size=224)\n",
        "test_dataset = PathMNIST(split='test', download=True, transform=transform, as_rgb=True, size=224)\n",
        "\n",
        "# DataLoader for training, validation, and testing\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "82EJJt3NrAjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import medmnist\n",
        "\n",
        "# Get info for PathMNIST\n",
        "info = medmnist.INFO['pathmnist']\n",
        "\n",
        "# Print the list of text labels\n",
        "print(\"Text labels for PathMNIST:\", info['label'])"
      ],
      "metadata": {
        "id": "NyU7hICAwCVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import medmnist\n",
        "\n",
        "def analyze_split(dataset, split_name):\n",
        "    \"\"\"Analyzes and plots label distribution for a given dataset split.\"\"\"\n",
        "    labels = dataset.labels\n",
        "\n",
        "    # Calculate label distribution\n",
        "    unique_labels, label_counts = np.unique(labels, return_counts=True)\n",
        "\n",
        "    # Get label text from the INFO dictionary in medmnist\n",
        "    info = medmnist.INFO['pathmnist']\n",
        "    label_text_values = list(info['label'].values())  # Get all values from label_text dictionary\n",
        "    # print (label_text_values)\n",
        "\n",
        "\n",
        "    # Plot label distribution using label text on x-axis\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.bar(range(len(unique_labels)), label_counts, color='skyblue')\n",
        "    plt.title(f'Label Distribution in PathMNIST {split_name} Set')\n",
        "    plt.xlabel('Labels')\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "    # Set x-axis ticks and labels using label_text values\n",
        "    plt.xticks(range(len(unique_labels)), label_text_values, rotation=45, ha='right')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Image distribution\n",
        "    print(f\"Image shape in {split_name} set:\", dataset[0][0].shape)\n",
        "    print(f\"Total number of images in {split_name} set:\", len(dataset))\n",
        "\n",
        "# Analyze each split\n",
        "analyze_split(train_dataset, \"Train\")\n",
        "analyze_split(val_dataset, \"Validation\")\n",
        "analyze_split(test_dataset, \"Test\")"
      ],
      "metadata": {
        "id": "0_DFQrkZhsTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get a glimpse into the dataset\n",
        "x, y = train_dataset[0]\n",
        "print(x.shape, y.shape)\n",
        "# torch.Size([3, 224, 224]) (1,)\n",
        "train_dataset.montage(length=3)"
      ],
      "metadata": {
        "id": "RvycT_HisKSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add this import statement at the beginning of your code:\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import medmnist\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import models\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define the Model with ResNet18 pretrained\n",
        "class PathMNISTClassifier(nn.Module):\n",
        "    def __init__(self, num_classes=9):  # PathMNIST has 9 classes\n",
        "        super(PathMNISTClassifier, self).__init__()\n",
        "        self.model = models.resnet18(pretrained=True)\n",
        "\n",
        "        # Modify the final fully connected layer to match the number of classes in PathMNIST\n",
        "        in_features = self.model.fc.in_features\n",
        "        self.model.fc = nn.Linear(in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Training loop with additional metrics (AUC, ACC)\n",
        "def train_model(model, train_loader, criterion, optimizer, device, num_epochs=10):\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    # Track metrics\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "    train_auc_scores = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        correct_preds = 0\n",
        "        total_preds = 0\n",
        "        all_labels = []\n",
        "        all_preds = []\n",
        "\n",
        "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(images)\n",
        "            labels = labels.squeeze(1)  # Remove the extra dimension\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct_preds += (predicted == labels).sum().item()\n",
        "            total_preds += labels.size(0)\n",
        "\n",
        "            # Store all labels and predictions for AUC calculation\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(torch.softmax(outputs, dim=1).cpu().detach().numpy())\n",
        "\n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "        accuracy = (correct_preds / total_preds) * 100\n",
        "        auc = roc_auc_score(np.array(all_labels), np.array(all_preds), multi_class='ovr', average='macro')\n",
        "\n",
        "        train_losses.append(avg_loss)\n",
        "        train_accuracies.append(accuracy)\n",
        "        train_auc_scores.append(auc)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_loss:.4f}, Train Accuracy: {accuracy:.2f}%, Train AUC: {auc:.4f}\")\n",
        "\n",
        "    return train_losses, train_accuracies, train_auc_scores\n",
        "\n",
        "# Validation loop with AUC and Accuracy\n",
        "def evaluate_model(model, val_loader, criterion, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Track metrics\n",
        "    val_losses = []\n",
        "    val_accuracies = []\n",
        "    val_auc_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        running_loss = 0.0\n",
        "        correct_preds = 0\n",
        "        total_preds = 0\n",
        "        all_labels = []\n",
        "        all_preds = []\n",
        "\n",
        "        for images, labels in tqdm(val_loader, desc=\"Evaluating\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            labels = labels.squeeze(1)  # Remove the extra dimension\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct_preds += (predicted == labels).sum().item()\n",
        "            total_preds += labels.size(0)\n",
        "\n",
        "            # Store all labels and predictions for AUC calculation\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(torch.softmax(outputs, dim=1).cpu().detach().numpy())\n",
        "\n",
        "        avg_loss = running_loss / len(val_loader)\n",
        "        accuracy = (correct_preds / total_preds) * 100\n",
        "        auc = roc_auc_score(np.array(all_labels), np.array(all_preds), multi_class='ovr', average='macro')\n",
        "\n",
        "        val_losses.append(avg_loss)\n",
        "        val_accuracies.append(accuracy)\n",
        "        val_auc_scores.append(auc)\n",
        "\n",
        "        print(f\"Validation Loss: {avg_loss:.4f}, Validation Accuracy: {accuracy:.2f}%, Validation AUC: {auc:.4f}\")\n",
        "\n",
        "    return val_losses, val_accuracies, val_auc_scores\n",
        "\n",
        "# Initialize Model, Loss, Optimizer\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = PathMNISTClassifier(num_classes=9)  # PathMNIST has 9 categories\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Track the best AUC\n",
        "best_auc = 0.0\n",
        "best_model_wts = None\n",
        "\n",
        "# Train the model and evaluate\n",
        "num_epochs = 15\n",
        "train_losses, train_accuracies, train_auc_scores = train_model(model, train_loader, criterion, optimizer, device, num_epochs=num_epochs)\n",
        "val_losses, val_accuracies, val_auc_scores = evaluate_model(model, val_loader, criterion, device)\n",
        "\n",
        "# Save the model if best AUC is achieved\n",
        "if val_auc_scores[-1] > best_auc:\n",
        "    best_auc = val_auc_scores[-1]\n",
        "    best_model_wts = model.state_dict()\n",
        "    torch.save(best_model_wts, '/content/drive/MyDrive/ColabNotebooks/pathmnist_224_best_auc_model.pth')\n"
      ],
      "metadata": {
        "id": "RPp-gbAVjrQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Plot the tracked metrics\n",
        "def plot_metrics(train_losses, train_accuracies, train_auc_scores, val_losses, val_accuracies, val_auc_scores):\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "    # Repeat the single validation metric value for each epoch to match lengths\n",
        "    val_losses = val_losses * len(epochs)\n",
        "    val_accuracies = val_accuracies * len(epochs)\n",
        "    val_auc_scores = val_auc_scores * len(epochs)\n",
        "\n",
        "    # Plot Train and Validation Loss\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, train_losses, label='Train Loss', color='blue')\n",
        "    plt.plot(epochs, val_losses, label='Validation Loss', color='red')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Train and Validation Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Train and Validation Accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, train_accuracies, label='Train Accuracy', color='blue')\n",
        "    plt.plot(epochs, val_accuracies, label='Validation Accuracy', color='red')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.title('Train and Validation Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Train and Validation AUC\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(epochs, train_auc_scores, label='Train AUC', color='blue')\n",
        "    plt.plot(epochs, val_auc_scores, label='Validation AUC', color='red')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('AUC')\n",
        "    plt.title('Train and Validation AUC')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "02N5DL2nK5Gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot all tracked metrics\n",
        "plot_metrics(train_losses, train_accuracies, train_auc_scores, val_losses, val_accuracies, val_auc_scores)\n",
        "\n",
        "# Optional: Visualize some test images with labels (as before)\n",
        "def plot_images_with_labels(loader, class_names):\n",
        "    data_iter = iter(loader)\n",
        "    images, labels = next(data_iter)\n",
        "    images = images.numpy().transpose((0, 2, 3, 1))  # Convert to HWC format\n",
        "\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(12, 6))\n",
        "    axes = axes.ravel() # Flatten axes to iterate through them\n",
        "    for i in range(6):\n",
        "        # axes[i] now refers to the correct subplot object\n",
        "        axes[i].imshow(images[i])\n",
        "        # Convert the label to a string to match the keys in class_names\n",
        "        label = class_names[str(labels[i].item())]\n",
        "        axes[i].set_title(f\"Label: {label}\")\n",
        "        axes[i].axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Class names for PathMNIST dataset (corresponding to the 9 classes)\n",
        "info = medmnist.INFO['pathmnist']\n",
        "class_names = info['label']  # Get class names from the INFO dictionary\n",
        "\n",
        "# Visualize some images from the test set with labels\n",
        "plot_images_with_labels(test_loader, class_names)"
      ],
      "metadata": {
        "id": "wDuxENZzK_1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import medmnist  # Make sure you have imported medmnist\n",
        "\n",
        "def show_two_images_per_label(dataset):\n",
        "    \"\"\"Displays two images for each label type in the dataset.\"\"\"\n",
        "\n",
        "    # Get class names from medmnist.INFO\n",
        "    class_names = medmnist.INFO['pathmnist']['label']\n",
        "    num_classes = len(class_names)  # Get the number of classes\n",
        "\n",
        "    # Create a dictionary to store images for each label\n",
        "    images_by_label = {}\n",
        "    for i in range(len(dataset)):\n",
        "        image, label = dataset[i]\n",
        "        label = label.item()  # Get the label as an integer\n",
        "\n",
        "        if label not in images_by_label:\n",
        "            images_by_label[label] = []\n",
        "\n",
        "        images_by_label[label].append(image)\n",
        "\n",
        "        # Stop collecting images for a label if we have 2\n",
        "        if len(images_by_label[label]) == 2:\n",
        "            continue\n",
        "\n",
        "    # Plot the images\n",
        "    fig, axes = plt.subplots(num_classes, 2, figsize=(12, 4 * num_classes))\n",
        "\n",
        "    for label in range(num_classes):\n",
        "        if label in images_by_label:\n",
        "            # Ensure i doesn't exceed the bounds of the axes array\n",
        "            for i, image in enumerate(images_by_label[label][:2]):  # Limit to 2 images\n",
        "                image = image.numpy().transpose((1, 2, 0))  # Transpose to HWC format\n",
        "                axes[label, i].imshow(image)\n",
        "                axes[label, i].set_title(f\"Label: {class_names[str(label)]}\")  # Use class_names for title\n",
        "                axes[label, i].axis('off')\n",
        "        else:\n",
        "            print(f\"No images found for label: {class_names[str(label)]}\")  # Use class_names for print statement\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Call the function to display the images\n",
        "show_two_images_per_label(train_dataset)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "1S3lhEPCNTB4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}